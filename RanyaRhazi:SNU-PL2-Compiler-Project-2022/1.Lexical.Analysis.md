# SnuPL/2 Compiler



## Logistics

### Work individually
The first phase of our term project is an individual assignment. This phase will allow you (and us) to assess your C++ and programming skills. 
This first phase is not evaluated based on functionality, but rather on effort. I.e., even if your scanner does not work at all, if we recognize you put sufficient effort into it, you will get full points for it.
We will form and work in teams starting with phase 2.

### Git
If you have never used Git before, you may want to have a look at one of the many tutorials out there.
W3Schools has a comprehensive, yet easy-to-understand [Git tutorial](https://www.w3schools.com/git/default.asp?remote=github).

### Hand-out
Start by forking the lab into your namespace, then **make sure that the lab's visibility is set to private**. 
Read the instructions here carefully. 
Finally, clone the lab to your local computer and get to work. 

### Submission

Commit locally and push your work to our server frequently to avoid data loss. 

Once you are happy with your implementation, create an annotated tag as follows
```bash
$ git tag -a phase1 -m "Submission Phase 1". 
```

Do not forget to push your tag to the server, otherwise we won't see it
```bash
$ git push origin --tags
```

If you have already tagged your code, but later discover a problem and want to update your submission, you can delete and re-create the tag.
This can be done [from the command line](https://devconnected.com/how-to-delete-local-and-remote-tags-on-git/) or via the GitLab web interface (Repository -> Tags). 
Do not forget to re-tag your updated code and push the tag to the server.

**The timestamp of the `phase1` tag constitutes your submission time**.

If you tag (i.e., submit) your code _after_ the submission deadline, you also need to email the TAs so that they are aware of the update to your submission.




## Phase 1: Lexical Analysis

In this first phase, your job is to implement a scanner for the SnuPL/2 language as specified in the
term project overview.

### Description
The scanner takes a character stream as its input and produces a stream of attributed tokens as its output. 

The scanner must correctly recognize and tokenize all keywords, identifiers, numbers, operators (assignment, binary and relational), comments, and the syntax elements of the SnuPL/2 language. 
The scanner should scan the input until the end of the input character stream is reached or an error is detected. 
The syntax of SnuPL/2 can be found [here](specification/SnuPL2.md).

The scanner must scan but ignore white-space and single-line comments. 
Character constants enclosed in single quotes and strings (enclosed in double quotes) must be recognized as a whole and returned to the parser as a single token with the token value set to the single character/character sequence.
Numbers are scanned as string and returned to the parser as a single token. 
The conversion string to number will later be performed in the parser, i.e., you need to return the lexeme (string) representing the number, not the number itself.


### Your Task
We provide a skeleton for a scanner/parser framework so that you don't have to write the entire framework from scratch and can focus only on the interesting parts. 
The provided skeleton code implements lexical analysis for the language "SnuPL/-1". 
SnuPL/-1 is a stripped down version of SnuPL/2 but will help you to understand how to use the SnuPL framework. 
The syntax definition of SnuPL/-1 is provided [here](specification/SnuPL-1.md).

The scanner skeleton can be found in the files `snuplc/src/scanner.[h/cpp]`. 

The header file defines the token type `EToken` that represents all classes of lexemes we implement. 
You will need to add additional tokens to this data type to implement SnuPL/2. 

There are two corresponding data structures (`ETokenName` and `ETokenStr`) that are used to output the token names in human-readable form in `scanner.cpp`. 
ETokenName contains the token type in string format, while ETokenStr can be used to print the token name along with its attributes (the lexeme).
Since the elements of ETokenStr are fed to printf, you can print the lexeme by inserting a `%s` placeholder somewhere in that string.

The token class `CToken` is fully implemented and functional, you do not have to modify it. 
The scanner `CScanner` is also fully functional, but only recognizes SnuPL/-1. 
You will need to modify the function `CToken* Scanner::Scan()` to accept all possible tokens of SnuPL/2.

Properly scanning characters and strings is quite difficult. For that reason, the skeleton contains a method `CScanner::GetCharacter()` that can be used to parse the (possibly escapted) characters in a string or character constant.

Last but not least, the sources also contain a simple test program to test your lexical analyzer.
The test program instaniates a `CScanner` object instance and repeatedly calls `CScanner::Get()` to retrieve and print the next token until the end of file is reached.

To build the test program, run the following command in the `snuplc/` directory
```bash
snuplc $ make test_scanner
```

You can invoke `test_scanner` with a file name as an argument:
```bash
snuplc $ ./test_scanner ../test/scanner/test01.mod
```

In the directory `test/scanner/` you will find a number of test files for the scanner. 
We advise you to create your own test cases to test special cases; we have our own set of test files to test (and grade) your scanner. 

A reference implementation is provided in the directory `snuplc/reference/`. 
You can use our reference implementation to compare the output of your scanner with ours. 
Note that we do not expect a 100% matching output - that is not the purpose of providing a reference implementation! 
Use your own judgement and common sense to decide what works for you.

**Hints**:  
The first phase is pretty straight-forward to implement. Two points are noteworthy:
* error recovery: unrecognized lexemes should be handled by returning a tUndefined token with the illegal lexeme or a custom error message as its attribute
* handling of comments and whitespace: consume all whitespace and comments in the scanner (i.e., do not return a token for whitespace or comments)


### Inline Documentation
Our SnuPL/2 compiler and the skeleton code are fully documented with Doxygen.
You can generate the documentation from your sources by running 
```bash
snuplc $ make doc
```
from the `snuplc` directory. You will need to install Doxygen and Graphviz (dot) on your machine.



### Materials to submit:
* Source code of the scanner  
  Document your code properly - including Doxygen comments for all new classes, member functions, and fields.
  Please do not include any generated files (documentation, relocateable object files, binaries) into your GitLab repository. We will compile your code by ourselves.

* A brief report describing your implementation of the scanner in PDF format  
  The report must be stored as `reports/1.Lexical.Analysis.pdf`.  
  You can use the reports from the individual phases to compiler your final report at the end of this semester.
  Note that the reports are almost as important as your code. Make sure to put sufficient effort into them!


## Final words
Implementing a compiler is difficult. Do noot hesitate to ask questions in class and on Slack. 
Also, start as soon as possible; if you wait until a few days before the deadline we cannot help you much and you may not be able to finish in time.

Happy coding!
